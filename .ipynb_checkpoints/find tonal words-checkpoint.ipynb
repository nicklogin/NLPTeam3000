{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu, os\n",
    "from ufal.udpipe import Model, Pipeline\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_words = dict()\n",
    "service_words = dict()\n",
    "\n",
    "with open('development/Food_words.txt', 'r', encoding='utf-8') as inp:\n",
    "    for line in inp.readlines():\n",
    "        aspect, word, score = line.strip().split('        ')\n",
    "        food_words[word] = score\n",
    "\n",
    "with open('development/Service_words.txt', 'r', encoding='utf-8') as inp:\n",
    "    for line in inp.readlines():\n",
    "        aspect, word, score = line.strip().split('\\t')\n",
    "        service_words[word] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'вкусный': '1',\n",
       " 'большой': '1',\n",
       " 'прекрасный': '1',\n",
       " 'разнообразный': '1',\n",
       " 'единственный': '1',\n",
       " 'достойный': '1',\n",
       " 'странный': '1',\n",
       " 'отличный': '1',\n",
       " 'горячий': '1',\n",
       " 'сытный': '1',\n",
       " 'свежий': '1',\n",
       " 'великолепный': '1',\n",
       " 'интересный': '1',\n",
       " 'различный': '1',\n",
       " 'необычный': '1',\n",
       " 'приятный': '1',\n",
       " 'плохой': '0',\n",
       " 'невкусный': '0',\n",
       " 'посредственно': '0',\n",
       " 'понравиться': '1'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'приветливый': '1',\n",
       " 'внимательный': '1',\n",
       " 'приятный': '1',\n",
       " 'вежливый': '1',\n",
       " 'хороший': '1',\n",
       " 'ненавязчивый': '1',\n",
       " 'доброжелательный': '1',\n",
       " 'дружелюбный': '1',\n",
       " 'хамоватый': '0',\n",
       " 'отличный': '1',\n",
       " 'милый': '1',\n",
       " 'гостеприимный': '1',\n",
       " 'качественный': '1',\n",
       " 'отзывчивый': '1',\n",
       " 'радушный': '1',\n",
       " 'красивый': '1',\n",
       " 'душевный': '1',\n",
       " 'веселый': '1',\n",
       " 'понравиться': '1',\n",
       " 'спасибо': '1'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12943.tsv\n",
      "13823.tsv\n",
      "20086.tsv\n",
      "28083.tsv\n",
      "32840.tsv\n",
      "32856.tsv\n",
      "33591.tsv\n",
      "33693.tsv\n",
      "35486.tsv\n",
      "5648.tsv\n"
     ]
    }
   ],
   "source": [
    "new_food_words = dict()\n",
    "new_service_words = dict()\n",
    "\n",
    "for file in os.listdir('разметка_финал'):\n",
    "    if file.endswith('.tsv'):\n",
    "        print(file)\n",
    "        \n",
    "        with open(os.path.join('разметка_финал',file), 'r', encoding='utf-8') as inp:\n",
    "            lines = inp.readlines()\n",
    "\n",
    "        conllu_path = os.path.join('conllu_data', file)\n",
    "        with open(conllu_path, 'r', encoding='utf-8') as inp:\n",
    "            conll = conllu.parse(inp.read())\n",
    "\n",
    "        for line in lines:\n",
    "            if line:\n",
    "                sent_id, token_ids, aspect, mark = line.strip().split('\\t')\n",
    "                mark = int(mark)\n",
    "                sent_id = int(sent_id)-1\n",
    "                token_ids = [int(i) for i in token_ids.split(',')]\n",
    "                start_id, end_id = int(token_ids[0])-1, int(token_ids[-1])\n",
    "                try:\n",
    "                    tokens = ' '.join(token['lemma'] for token in conll[sent_id][start_id:end_id])\n",
    "                except:\n",
    "                    print(sent_id, start_id, end_id)\n",
    "                if aspect.strip() == 'Service' and tokens not in new_service_words:\n",
    "                    new_service_words[tokens] = mark\n",
    "                elif aspect.strip() == 'Food' and tokens not in new_food_words:\n",
    "                    new_food_words[tokens] = mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'отличный': 1,\n",
       " 'очень вкусный': 1,\n",
       " 'сытный': 1,\n",
       " 'разнообразный вкусный': 1,\n",
       " 'не впечатлять': 0,\n",
       " 'вкусный': 1,\n",
       " 'высокий все похвасть': 1,\n",
       " 'прекрасный': 1,\n",
       " 'хороший': 1,\n",
       " '10 балл': 1,\n",
       " 'понравиться': 1,\n",
       " 'нежный': 1,\n",
       " 'впечатлять': 1,\n",
       " 'очень большой': 1,\n",
       " 'вкусно': 1,\n",
       " 'не очень дорого': 1,\n",
       " 'большой': 1,\n",
       " 'расстроить': 0,\n",
       " 'невкусный': 0,\n",
       " 'совершенно отвратительный': 0,\n",
       " 'весь остыть': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_food_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'очень приветливый': 1,\n",
       " 'ненавязчивый': 1,\n",
       " 'оперативный': 1,\n",
       " 'недолгий': 1,\n",
       " 'вполне приемлимый': 1,\n",
       " 'высокий качество': 1,\n",
       " 'хороший': 1,\n",
       " 'вежливый': 1,\n",
       " 'оперативность': 1,\n",
       " 'приятный': 1,\n",
       " 'улыбчивый': 1,\n",
       " 'трепетный': 1,\n",
       " 'хамоватый': 0,\n",
       " 'с вызов': 0,\n",
       " 'не слишком вежливо': 0,\n",
       " 'ужасный': 0,\n",
       " 'плохо знать меню': 0,\n",
       " 'хорошо обучить': 1,\n",
       " 'очень аккуратно': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_service_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на пересечения выделенных нами словарей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'большой',\n",
       " 'вкусный',\n",
       " 'невкусный',\n",
       " 'отличный',\n",
       " 'понравиться',\n",
       " 'прекрасный',\n",
       " 'сытный'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(food_words) & set(new_food_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'вежливый', 'ненавязчивый', 'приятный', 'хамоватый', 'хороший'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(service_words) & set(new_service_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И на их разницу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10 балл',\n",
       " 'весь остыть',\n",
       " 'вкусно',\n",
       " 'впечатлять',\n",
       " 'высокий все похвасть',\n",
       " 'не впечатлять',\n",
       " 'не очень дорого',\n",
       " 'нежный',\n",
       " 'очень большой',\n",
       " 'очень вкусный',\n",
       " 'разнообразный вкусный',\n",
       " 'расстроить',\n",
       " 'совершенно отвратительный',\n",
       " 'хороший'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_food_words) - set(food_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'великолепный',\n",
       " 'горячий',\n",
       " 'достойный',\n",
       " 'единственный',\n",
       " 'интересный',\n",
       " 'необычный',\n",
       " 'плохой',\n",
       " 'посредственно',\n",
       " 'приятный',\n",
       " 'различный',\n",
       " 'разнообразный',\n",
       " 'свежий',\n",
       " 'странный'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(food_words) - set(new_food_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'вполне приемлимый',\n",
       " 'высокий качество',\n",
       " 'не слишком вежливо',\n",
       " 'недолгий',\n",
       " 'оперативность',\n",
       " 'оперативный',\n",
       " 'очень аккуратно',\n",
       " 'очень приветливый',\n",
       " 'плохо знать меню',\n",
       " 'с вызов',\n",
       " 'трепетный',\n",
       " 'ужасный',\n",
       " 'улыбчивый',\n",
       " 'хорошо обучить'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(new_service_words) - set(service_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'веселый',\n",
       " 'внимательный',\n",
       " 'гостеприимный',\n",
       " 'доброжелательный',\n",
       " 'дружелюбный',\n",
       " 'душевный',\n",
       " 'качественный',\n",
       " 'красивый',\n",
       " 'милый',\n",
       " 'отзывчивый',\n",
       " 'отличный',\n",
       " 'понравиться',\n",
       " 'приветливый',\n",
       " 'радушный',\n",
       " 'спасибо'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(service_words) - set(new_service_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 34)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(service_words) | set(new_service_words)), len(set(food_words) | set(new_food_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 21, 20, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_service_words), len(new_food_words), len(food_words), len(service_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.ipynb_checkpoints',\n",
       " '12943.xlsx',\n",
       " '13823.xlsx',\n",
       " '20086.xlsx',\n",
       " '28083.xlsx',\n",
       " '32840.xlsx',\n",
       " '32856.xlsx',\n",
       " '33591.xlsx',\n",
       " '33693.xlsx',\n",
       " '35486.xlsx',\n",
       " '5648.xlsx',\n",
       " 'conllu_data',\n",
       " 'convert to needed format.ipynb',\n",
       " 'convert.py',\n",
       " 'development',\n",
       " 'example.csv',\n",
       " 'find keywords.ipynb',\n",
       " 'find tonal words.ipynb',\n",
       " 'README.md',\n",
       " 'разметка_финал',\n",
       " 'Реферат.docx',\n",
       " 'условия']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "hub.load() is not implemented for TF < 1.14.x, Current version: 1.13.1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-741fc251d2bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0melmo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/elmo_model_lemmatized_rusvectores'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_hub\\module_v2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(handle, tags)\u001b[0m\n\u001b[0;32m     87\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_v1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"load_v2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     raise NotImplementedError(\"hub.load() is not implemented for TF < 1.14.x, \"\n\u001b[1;32m---> 89\u001b[1;33m                               \"Current version: %s\" % tf.__version__)\n\u001b[0m\u001b[0;32m     90\u001b[0m   \u001b[0mmodule_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m   is_hub_module_v1 = tf.io.gfile.exists(\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: hub.load() is not implemented for TF < 1.14.x, Current version: 1.13.1"
     ]
    }
   ],
   "source": [
    "elmo = hub.load('/elmo_model_lemmatized_rusvectores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Module in module tensorflow_hub.module:\n",
      "\n",
      "class Module(builtins.object)\n",
      " |  Module(spec, trainable=False, name='module', tags=None)\n",
      " |  \n",
      " |  Part of a TensorFlow 1 model that can be transferred between models.\n",
      " |  \n",
      " |  DEPRECATION NOTE: The hub.Module API and file format works for TF1 only.\n",
      " |  For TF2, switch to plain SavedModels and hub.load().\n",
      " |  \n",
      " |  A Module represents a part of a TensorFlow graph that can be exported to disk\n",
      " |  (based on the SavedModel format) and later re-loaded. A Module has a defined\n",
      " |  interface that allows it to be used in a replaceable way, with little or no\n",
      " |  knowledge of its internals and its serialization format. Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  m = hub.Module(\"/tmp/text-embedding\")\n",
      " |  embeddings = m(sentences)\n",
      " |  ```\n",
      " |  \n",
      " |  The module to instantiate is defined by its spec (a `ModuleSpec` or a\n",
      " |  path where to load it from) which contains the module weights, assets and\n",
      " |  signatures.\n",
      " |  \n",
      " |  During instantiation the Module adds the state (e.g. variables and tables ops)\n",
      " |  to the current graph. Afterwards, the method `__call__()` allows to apply the\n",
      " |  module `signatures` multiple times, which adds ops for the computation.\n",
      " |  \n",
      " |  A Module may provide different variants of its graph for different purposes\n",
      " |  (say, training or serving, which may behave differently, e.g., for batch\n",
      " |  normalization). Graph variants are identified by sets of string-valued tags.\n",
      " |  The graph variant used to create a module that is exported must define all the\n",
      " |  variables needed by any other graph variant that is subsequently used.\n",
      " |  \n",
      " |  To make it possible to easily replace a module with another, they all assume\n",
      " |  that they will be used with common TensorFlow conventions such as session\n",
      " |  initialization and restore, use of collections for variables, regularization\n",
      " |  losses and updates, etc.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __call__(self, inputs=None, _sentinel=None, signature=None, as_dict=None)\n",
      " |      Instantiates a module signature in the graph.\n",
      " |      \n",
      " |      Example calls:\n",
      " |      \n",
      " |      ```python\n",
      " |        # Use default signature with one input and default output.\n",
      " |        embeddings = m([\"hello world\", \"good morning\"])\n",
      " |      \n",
      " |        # Use \"encode\" signature with one input and default output.\n",
      " |        encodings = m([\"hello world\"], signature=\"encode\")\n",
      " |      \n",
      " |        # Use default signature with input dict and output dict.\n",
      " |        dict_outputs = m({\"text\": [...], \"lang\": [...]}, as_dict=True)\n",
      " |      ```\n",
      " |      \n",
      " |      The method __call__() allows to create the graph ops that compute a\n",
      " |      signature outputs given the inputs and using this module instance state.\n",
      " |      Each signature can be applied multiple times with different inputs and they\n",
      " |      all share the same module state.\n",
      " |      \n",
      " |      A Module may define multiple signatures. Use `signature=<name>` to identify\n",
      " |      the specific signature to instantiate. If omitted or None, the default\n",
      " |      signature is used.\n",
      " |      \n",
      " |      A signature may define various outputs. Use `as_dict=True` to return a dict\n",
      " |      of all outputs. If omitted or False, the output named 'default' is\n",
      " |      returned.\n",
      " |      \n",
      " |      During this call a Module will:\n",
      " |      \n",
      " |      - Add ops in the current name scope to convert the inputs in tensors to feed\n",
      " |        to the signature.\n",
      " |      \n",
      " |      - Add ops to the UPDATE_OPS collection which depend on at least one of the\n",
      " |        provided inputs if the Module was constructed with `trainable=True`.\n",
      " |      \n",
      " |      - Add constant tensors to ASSET_FILEPATHS, even if those are not needed\n",
      " |        directly needed for the signature.\n",
      " |      \n",
      " |      Note: `hub.Module` implementation depends on graph pruning that happens\n",
      " |      usually during `session.run` as so it can lead to errors when used inside\n",
      " |      function graphs that execute all its ops (e.g. `tf.data.Dataset.map`).\n",
      " |      \n",
      " |      Args:\n",
      " |        inputs: Inputs to the signature. A dict from input names to tensor\n",
      " |          values. If the signature only expects one input, one may pass\n",
      " |          a single value. If the signature has no inputs, it may be omitted.\n",
      " |        _sentinel: Used to prevent positional parameters besides `inputs`.\n",
      " |        signature: A string with the signature name to apply. If none, the\n",
      " |          default signature is used.\n",
      " |        as_dict: A boolean indicating whether to the return all the outputs\n",
      " |          of the signature as a dict or return only the default output.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A tensor (single or sparse) if the signature defines a default output or\n",
      " |        a dict from strings (output names) to tensors if `as_dict=True` is used.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If there is a mismatch on arguments, inputs or outputs of\n",
      " |          the module signature.\n",
      " |        RuntimeError: If there are errors during creation of the signature graph.\n",
      " |  \n",
      " |  __init__(self, spec, trainable=False, name='module', tags=None)\n",
      " |      Constructs a Module to be used in the current graph.\n",
      " |      \n",
      " |      This creates the module `state-graph` under an unused variable_scope based\n",
      " |      on `name`. During this call a Module will:\n",
      " |      \n",
      " |      - Add GLOBAL_VARIABLES under its scope. Those variables may be added to\n",
      " |        to the TRAINABLE_VARIABLES collection (depending on `trainable` parameter)\n",
      " |        and to the MODEL_VARIABLES. The variables must be initialized before use,\n",
      " |        and can be checkpointed as usual.\n",
      " |      \n",
      " |      - Add ops to the INIT_TABLE_OPS collection, which must be run during session\n",
      " |        initialization and add constant tensors to ASSET_FILEPATHS that are\n",
      " |        needed during the execution of such ops.\n",
      " |      \n",
      " |      - Add tensors to the REGULARIZATION_LOSSES collection (depending on\n",
      " |        `trainable` parameter).\n",
      " |      \n",
      " |      Args:\n",
      " |        spec: A ModuleSpec defining the Module to instantiate or a path where\n",
      " |          to load a ModuleSpec from via `load_module_spec`.\n",
      " |        trainable: whether the Module is trainable. If False, no variables are\n",
      " |          added to TRAINABLE_VARIABLES collection, and no tensors are added to\n",
      " |          REGULARIZATION_LOSSES collection.\n",
      " |        name: A string, the variable scope name under which to create the Module.\n",
      " |          It will be uniquified and the equivalent name scope must be unused.\n",
      " |        tags: A set of strings specifying the graph variant to use.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: explaning the reason why it failed to instantiate the\n",
      " |          Module.\n",
      " |        ValueError: if the requested graph variant does not exists.\n",
      " |        tf.errors.NotFoundError: if the requested graph contains unknown ops.\n",
      " |  \n",
      " |  export(self, path, session)\n",
      " |      Exports the module with the variables from the session in `path`.\n",
      " |      \n",
      " |      Note that it is the module definition in the ModuleSpec used to create this\n",
      " |      module that gets exported. The session is only used to provide the value\n",
      " |      of variables.\n",
      " |      \n",
      " |      Args:\n",
      " |        path: path where to export the module to.\n",
      " |        session: session where to export the variables from.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: if there is an issue during the export.\n",
      " |  \n",
      " |  get_attached_message(self, key, message_type, required=False)\n",
      " |      Calls ModuleSpec.get_attached_message(); see there for more.\n",
      " |  \n",
      " |  get_input_info_dict(self, signature=None)\n",
      " |      Describes the inputs required by a signature.\n",
      " |      \n",
      " |      Args:\n",
      " |        signature: A string with the signature to get inputs information for.\n",
      " |          If None, the default signature is used if defined.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The result of ModuleSpec.get_input_info_dict() for the given signature,\n",
      " |        and the graph variant selected by `tags` when this Module was initialized.\n",
      " |      \n",
      " |      Raises:\n",
      " |        KeyError: if there is no such signature.\n",
      " |  \n",
      " |  get_output_info_dict(self, signature=None)\n",
      " |      Describes the outputs provided by a signature.\n",
      " |      \n",
      " |      Args:\n",
      " |        signature: A string with the signature to get ouputs information for.\n",
      " |          If None, the default signature is used if defined.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The result of ModuleSpec.get_output_info_dict() for the given signature,\n",
      " |        and the graph variant selected by `tags` when this Module was initialized.\n",
      " |      \n",
      " |      Raises:\n",
      " |        KeyError: if there is no such signature.\n",
      " |  \n",
      " |  get_signature_names(self)\n",
      " |      Returns the module's signature names as an iterable of strings.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  variable_map\n",
      " |      Map from original variable names into tf.Variables (or lists of them).\n",
      " |      \n",
      " |      This map translates between variable names relative to the module and the\n",
      " |      corresponding Variable objects that have been created by instantiating it\n",
      " |      in the current graph (with the applicable scoping added). Each key in the\n",
      " |      map is a variable name as created by running the module's defining\n",
      " |      `module_fn` in the root scope of an empty graph. Each value in the map is\n",
      " |      a Variable object, or in case of partitioned variables a list of Variable\n",
      " |      objects.\n",
      " |      \n",
      " |      This property can be used with `tf.init_from_checkpoint` as `assignment_map`\n",
      " |      in order to restore a pre-trained checkpoint into a Module before calling\n",
      " |      `Module.export()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A dict from the variable names in the Module to the instantiated\n",
      " |        tf.Variables or list of tf.Variables (if partitioned). The keys of this\n",
      " |        map are the same regardless of the scope of where the Module was\n",
      " |        instantiated.\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all tf.Variables created by module instantiation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hub.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load in module tensorflow_hub.module_v2:\n",
      "\n",
      "load(handle, tags=None)\n",
      "    Resolves a handle and loads the resulting module.\n",
      "    \n",
      "    This is the preferred API to load a Hub module in low-level TensorFlow 2.\n",
      "    Users of higher-level frameworks like Keras should use the framework's\n",
      "    corresponding wrapper, like hub.KerasLayer.\n",
      "    \n",
      "    This function is roughly equivalent to the TF2 function `tf.save_model.load()`\n",
      "    on the result of `hub.resolve(handle)`. Calling this function requires\n",
      "    TF 1.14 or newer. It can be called both in eager and graph mode.\n",
      "    \n",
      "    This function can handle the deprecated hub.Module format to the extent\n",
      "    that `tf.save_model.load()` in TF2 does. In particular, the returned object\n",
      "    has attributes\n",
      "      * `.variables`: a list of variables from the loaded object;\n",
      "      * `.signatures`: a dict of TF2 ConcreteFunctions, keyed by signature names,\n",
      "        that take tensor kwargs and return a tensor dict.\n",
      "    However, the information imported by hub.Module into the collections of a\n",
      "    tf.Graph is lost (e.g., regularization losses and update ops).\n",
      "    \n",
      "    Args:\n",
      "      handle: (string) the Module handle to resolve; see hub.resolve().\n",
      "      tags: A set of strings specifying the graph variant to use, if loading from\n",
      "        a v1 module.\n",
      "    \n",
      "    Returns:\n",
      "      A trackable object (see tf.saved_model.load() documentation for details).\n",
      "    \n",
      "    Raises:\n",
      "      NotImplementedError: If the code is running against incompatible (1.x)\n",
      "                           version of TF.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hub.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
